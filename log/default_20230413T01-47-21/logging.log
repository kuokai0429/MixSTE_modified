Evaluate!
python run.py --custom_2d -d custom -k myvideos -f 81 -s 81 -c checkpoint --evaluate checkpoint_cpn_243f_paper.bin --render --viz-subject myvideos.mp4 --viz-action custom --viz-camera 0 --viz-export output --viz-video ./inference/input/myvideos.mp4 --viz-output output.mp4 --viz-size 6
CUDA Device Count:  1
Namespace(actions='*', alpha=0.01, batch_size=1024, beta=2, bone_length_term=True, by_subject=False, checkpoint='checkpoint', checkpoint_frequency=20, compare=False, coverlr=False, cs=512, custom_2d=True, data_augmentation=True, dataset='custom', dense=False, dep=8, depth=4, disable_optimizations=False, downsample=1, dropout=0.0, epochs=120, evaluate='checkpoint_cpn_243f_paper.bin', export_training_curves=False, ft=False, ftchk='epoch_330.pth', ftpath='checkpoint/exp13_ft2d', ftpostrf=False, gpu='0', keypoints='myvideos', learning_rate=4e-05, linear_channel_size=1024, linear_projection=False, log='log/default', lr_decay=0.99, lr_decay_gap=10000, min_loss=100000, no_eval=False, no_proj=False, nolog=False, number_of_frames=81, postrf=False, render=True, resume='', stride=81, subjects_test='S9,S11', subjects_train='S1,S5,S6,S7,S8', subjects_unlabeled='', subset=1, test_time_augmentation=True, viz_action='custom', viz_bitrate=3000, viz_camera=0, viz_downsample=1, viz_export='output', viz_limit=-1, viz_no_ground_truth=False, viz_output='output.mp4', viz_size=6, viz_skip=0, viz_subject='myvideos.mp4', viz_video='./inference/input/myvideos.mp4', warmup=1)
Loading dataset...
Preparing data...
Loading 2D detections...
Translate coco to h36m...
INFO: Receptive field: 81 frames
INFO: Trainable parameter count: 33.700867 Million
Loading checkpoint checkpoint/checkpoint_cpn_243f_paper.bin
This model was trained for 191 epochs
